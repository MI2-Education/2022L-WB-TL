{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JmQ102pjyuXF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDyQQNUZ23HC"
   },
   "source": [
    "# Części do sieci neuronowej\n",
    "\n",
    "\n",
    "*   https://github.com/milesial/Pytorch-UNet/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dmdDiORM29Gl"
   },
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class FirstHalfEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            Conv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels):\n",
    "    super().__init__()\n",
    "    self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2, padding=2)\n",
    "    self.conv1 = Conv(in_channels, in_channels)\n",
    "    self.conv2 = Conv(2*in_channels, in_channels)\n",
    "\n",
    "\n",
    "  def forward(self, x1, x2):\n",
    "\n",
    "    x1 = self.conv1(x1)\n",
    "\n",
    "    diffY = x2.size()[2] - x1.size()[2]\n",
    "    diffX = x2.size()[3] - x1.size()[3]\n",
    "    x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "    x = torch.cat([x2, x1], dim=1)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    return self.up(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels):\n",
    "    super().__init__()\n",
    "    self.outlayer = nn.Sequential( \n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=(2,1), padding=(4,3)),\n",
    "        nn.Sigmoid())\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.outlayer(x)\n",
    "\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "  def __init__(self, n_channels):\n",
    "    super().__init__()\n",
    "    n_channels *=2\n",
    "    self.r1 = nn.Sequential(\n",
    "        Conv(n_channels, n_channels),\n",
    "        nn.Conv2d(n_channels, n_channels, kernel_size=1, bias=False)\n",
    "    )\n",
    "    self.r3 = nn.Sequential(\n",
    "        Conv(n_channels, n_channels),\n",
    "        nn.Conv2d(n_channels, n_channels, kernel_size=1, bias=False)\n",
    "    )\n",
    "    self.r5 = nn.Sequential(\n",
    "        Conv(n_channels, n_channels),\n",
    "        nn.Conv2d(n_channels, n_channels, kernel_size=1, bias=False)\n",
    "    )\n",
    "    self.r7 = nn.Sequential(\n",
    "        Conv(n_channels, n_channels),\n",
    "        nn.Conv2d(n_channels, n_channels, kernel_size=1, bias=False)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    x1 = self.r1(x)\n",
    "    x3 = self.r3(x)\n",
    "    x5 = self.r5(x)\n",
    "    x7 = self.r7(x)\n",
    "\n",
    "    x_out = torch.add(torch.add(torch.add(x1, x3), x5), x7)\n",
    "\n",
    "    return torch.mul(x, x_out)\n",
    "\n",
    "class ChannelAttetnion(nn.Module):\n",
    "\n",
    "  def __init__(self, n_channels):\n",
    "    super().__init__()\n",
    "\n",
    "    self.blocks = nn.Sequential(\n",
    "        nn.AvgPool2d(1),\n",
    "        nn.Conv2d(n_channels, n_channels, kernel_size=1, bias=False),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(n_channels, n_channels, kernel_size=1, bias=False),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    x_out = self.blocks(x)\n",
    "    return torch.mul(x, x_out)\n",
    "\n",
    "class FusionBlock(nn.Module):\n",
    "  def __init__(self, n_channels):\n",
    "    super().__init__()\n",
    "\n",
    "    self.channelatt1 = ChannelAttetnion(n_channels)\n",
    "    self.channelatt2 = ChannelAttetnion(n_channels)\n",
    "    self.spatial = SpatialAttention(n_channels)\n",
    "    self.outlayers = Conv(2*n_channels, n_channels)\n",
    "\n",
    "  def forward(self, x1, x2):\n",
    "\n",
    "    x1 = self.channelatt1(x1)\n",
    "    x2 = self.channelatt2(x2)\n",
    "    \n",
    "\n",
    "    x = torch.cat([x1, x2], dim=1)\n",
    "\n",
    "\n",
    "    x = self.spatial(x)\n",
    "\n",
    "\n",
    "    x = self.outlayers(x)\n",
    "\n",
    "\n",
    "\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsuwRe7b-uop"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "D7Exo50q4XO_"
   },
   "outputs": [],
   "source": [
    "class MSCNet(nn.Module):\n",
    "  def __init__(self, n_channels, n_classes = 1):\n",
    "    super().__init__()\n",
    "    self.n_channels = n_channels\n",
    "    self.n_classes = n_classes\n",
    "\n",
    "    ## unets\n",
    "    # unet1\n",
    "    self.beginning_conv_top = nn.Conv2d(self.n_channels, 64, kernel_size=3)\n",
    "    \n",
    "    # block 1 down\n",
    "    self.enc1a_top = FirstHalfEncoder(64,128)\n",
    "    self.enc1b_top = Conv(128,128)\n",
    "\n",
    "    # block 2 down\n",
    "    self.enc2a_top = FirstHalfEncoder(128,256)\n",
    "    self.enc2b_top = Conv(256,256)\n",
    "\n",
    "    # block 3 down\n",
    "    self.enc3a_top = FirstHalfEncoder(256,512)\n",
    "    self.enc3b_top = Conv(512,512)\n",
    "\n",
    "    # block 4 down\n",
    "    self.enc4a_top = FirstHalfEncoder(512,1024)\n",
    "    self.enc4b_top = Conv(1024,1024)\n",
    "\n",
    "    # block 4 up\n",
    "    self.dec4_top = Decoder(1024, 512)\n",
    "    self.dec3_top = Decoder(512, 256)\n",
    "    self.dec2_top = Decoder(256, 128)\n",
    "    self.dec1_top = Decoder(128, 64)\n",
    "\n",
    "    # output\n",
    "\n",
    "    self.out_top = OutConv(64, n_classes)\n",
    "\n",
    "    # unet2\n",
    "    \n",
    "    self.beginning_conv_bot = nn.Conv2d(self.n_channels, 64, kernel_size=3)\n",
    "    \n",
    "    # block 1 down\n",
    "    self.enc1a_bot = FirstHalfEncoder(64,128)\n",
    "    self.enc1b_bot = Conv(128,128)\n",
    "\n",
    "    # block 2 down\n",
    "    self.enc2a_bot = FirstHalfEncoder(128,256)\n",
    "    self.enc2b_bot = Conv(256,256)\n",
    "\n",
    "    # block 3 down\n",
    "    self.enc3a_bot = FirstHalfEncoder(256,512)\n",
    "    self.enc3b_bot = Conv(512,512)\n",
    "\n",
    "    # block 4 down\n",
    "    self.enc4a_bot = FirstHalfEncoder(512,1024)\n",
    "    self.enc4b_bot = Conv(1024,1024)\n",
    "\n",
    "    # block 4 up\n",
    "    self.dec4_bot = Decoder(1024, 512)\n",
    "    self.dec3_bot = Decoder(512, 256)\n",
    "    self.dec2_bot = Decoder(256, 128)\n",
    "    self.dec1_bot = Decoder(128, 64)\n",
    "\n",
    "    # output\n",
    "\n",
    "    self.out_bot = OutConv(64, n_classes)\n",
    "\n",
    "    ## fusion\n",
    "\n",
    "    self.fusion4 = FusionBlock(1024)\n",
    "    self.fusion3 = FusionBlock(512)\n",
    "    self.fusion2 = FusionBlock(256)\n",
    "    self.fusion1 = FusionBlock(128)\n",
    "\n",
    "    self.sigmoid_top = nn.Sigmoid()\n",
    "    self.sigmoid_bot = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "    \n",
    "    x_init_top = self.beginning_conv_top(x)\n",
    "    x1a_top = self.enc1a_top(x_init_top)\n",
    "    x1b_top = self.enc1b_top(x1a_top)\n",
    "\n",
    "    x2a_top = self.enc2a_top(x1b_top)\n",
    "    x2b_top = self.enc2b_top(x2a_top)\n",
    "\n",
    "    x3a_top = self.enc3a_top(x2b_top)\n",
    "    x3b_top = self.enc3b_top(x3a_top)\n",
    "\n",
    "    x4a_top = self.enc4a_top(x3b_top)\n",
    "    x4b_top = self.enc4b_top(x4a_top)\n",
    "\n",
    "    x_init_bot = self.beginning_conv_bot(x)    \n",
    "    x1a_bot = self.enc1a_bot(x_init_bot)\n",
    "    x1b_bot = self.enc1b_bot(x1a_bot)\n",
    "\n",
    "    x2a_bot = self.enc2a_bot(x1b_bot)\n",
    "    x2b_bot = self.enc2b_bot(x2a_bot)\n",
    "\n",
    "    x3a_bot = self.enc3a_bot(x2b_bot)\n",
    "    x3b_bot = self.enc3b_bot(x3a_bot)\n",
    "\n",
    "    x4a_bot = self.enc4a_bot(x3b_bot)\n",
    "    x4b_bot = self.enc4b_bot(x4a_bot)\n",
    "\n",
    "    fusion4 = self.fusion4(x4b_top, x4b_bot)\n",
    "\n",
    "    x4_top = torch.add(x4b_top, fusion4)\n",
    "    x4_bot = torch.add(x4b_bot, fusion4)\n",
    "\n",
    "    x4_top = self.dec4_top(x4_top, x4a_top)\n",
    "    x4_bot = self.dec4_bot(x4_bot, x4a_bot)\n",
    "\n",
    "    fusion3 = self.fusion3(x4_top, x4_bot)\n",
    "\n",
    "    x3_top = torch.add(x4_top, fusion3)        \n",
    "    x3_bot = torch.add(x4_bot, fusion3)        \n",
    "\n",
    "    x3_top = self.dec3_top(x3_top, x3a_top)\n",
    "    x3_bot = self.dec3_bot(x3_bot, x3a_bot)\n",
    "\n",
    "    fusion2 = self.fusion2(x3_top, x3_bot)\n",
    "\n",
    "    x2_top = torch.add(x3_top, fusion2)\n",
    "    x2_bot = torch.add(x3_bot, fusion2)\n",
    "\n",
    "    x2_top = self.dec2_top(x2_top, x2a_top)\n",
    "    x2_bot = self.dec2_bot(x2_bot, x2a_bot)\n",
    "\n",
    "    fusion1 = self.fusion1(x2_top, x2_bot)\n",
    "\n",
    "    x1_top = torch.add(x2_top, fusion1)\n",
    "    x1_bot = torch.add(x2_bot, fusion1)\n",
    "\n",
    "    x1_top = self.dec1_top(x1_top, x1a_top)\n",
    "    x1_bot = self.dec1_bot(x1_bot, x1a_bot)\n",
    "\n",
    "    x_top = self.out_top(x1_top)\n",
    "    x_top = self.sigmoid_top(x_top)\n",
    "\n",
    "    x_bot = self.out_top(x1_bot)\n",
    "    x_bot = self.sigmoid_bot(x_bot)\n",
    "\n",
    "    return x_top, x_bot\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UjwISbOGcYRA"
   },
   "outputs": [],
   "source": [
    "class DataLoaderSegmentation(torch.utils.data.Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        super(DataLoaderSegmentation, self).__init__()\n",
    "        self.img_files = glob.glob(os.path.join(folder_path,'images','*.ppm'))\n",
    "        self.mask1_files = []\n",
    "        self.mask2_files = []\n",
    "        self.transform = transform\n",
    "        for img_path in self.img_files:\n",
    "             self.mask1_files.append(os.path.join(folder_path,'mask1',os.path.basename(img_path)))\n",
    "        for img_path in self.img_files:\n",
    "             self.mask2_files.append(os.path.join(folder_path,'mask2',os.path.basename(img_path)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "            img_path = self.img_files[index]\n",
    "            mask1_path = self.mask1_files[index]\n",
    "            data =Image.open(img_path)\n",
    "            mask1 = Image.open(mask1_path)\n",
    "            mask2_path = self.mask2_files[index]\n",
    "            mask2 = Image.open(mask2_path)\n",
    "\n",
    "            if self.transform:\n",
    "              img = self.transform(torch.from_numpy(numpy.asarray(data)/255).float())\n",
    "              m1 = self.transform(torch.from_numpy(numpy.asarray(mask1)/255).float())\n",
    "              m2 = self.transform(torch.from_numpy(numpy.asarray(mask2)/255).float())\n",
    "            else:\n",
    "              img = torch.from_numpy(numpy.asarray(data)/255).float()\n",
    "              m1 = torch.from_numpy(numpy.asarray(mask1)/255).float()\n",
    "              m2 = torch.from_numpy(numpy.asarray(mask2)/255).float()\n",
    "\n",
    "            img = img.permute(2, 0, 1)\n",
    "            return img, m1, m2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q02CCfMbghvQ",
    "outputId": "e688ecd9-0268-4c8b-b3ae-dd3a6681cecd",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1,sample:     1] loss: 1.99478018283844\n",
      "[Epoch: 1,sample:     2] loss: 1.9960351586341858\n",
      "[Epoch: 1,sample:     3] loss: 1.951777458190918\n",
      "[Epoch: 1,sample:     4] loss: 1.9273979365825653\n",
      "[Epoch: 1,sample:     5] loss: 1.9066287755966187\n",
      "[Epoch: 1,sample:     6] loss: 1.8963579138120015\n",
      "[Epoch: 1,sample:     7] loss: 1.8877010175159998\n",
      "[Epoch: 1,sample:     8] loss: 1.888973891735077\n",
      "[Epoch: 1,sample:     9] loss: 1.882885668012831\n",
      "[Epoch: 1,sample:    10] loss: 1.8786437273025514\n",
      "[Epoch: 1,sample:    11] loss: 1.8755618658932773\n",
      "[Epoch: 1,sample:    12] loss: 1.8741651972134907\n",
      "[Epoch: 1,sample:    13] loss: 1.8755379640139067\n",
      "[Epoch: 1,sample:    14] loss: 1.8737242903028215\n",
      "[Epoch: 1,sample:    15] loss: 1.8733115673065186\n",
      "[Epoch: 2,sample:     1] loss: 1.8404101133346558\n",
      "[Epoch: 2,sample:     2] loss: 1.8539645671844482\n",
      "[Epoch: 2,sample:     3] loss: 1.8437788089116414\n",
      "[Epoch: 2,sample:     4] loss: 1.8453617990016937\n",
      "[Epoch: 2,sample:     5] loss: 1.8452625036239625\n",
      "[Epoch: 2,sample:     6] loss: 1.8530446887016296\n",
      "[Epoch: 2,sample:     7] loss: 1.8518472228731429\n",
      "[Epoch: 2,sample:     8] loss: 1.8575864881277084\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 7\n",
    "\n",
    "net = MSCNet(n_channels = 3, n_classes = 1)\n",
    "\n",
    "dataset = DataLoaderSegmentation(\".\")\n",
    "\n",
    "train, test = torch.utils.data.random_split(dataset, [15,5], generator = torch.Generator().manual_seed(123))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, shuffle=True, batch_size=1, num_workers=0, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, shuffle=False, batch_size=1, num_workers=0, pin_memory=True, drop_last=True)\n",
    "\n",
    "optimizer = optim.RMSprop(net.parameters(), lr = 1e-3, weight_decay=1e-8, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "  running_loss = 0.0\n",
    "  net.train()\n",
    "  for i, (image, mask1, mask2) in enumerate(train_loader):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output_top, output_bot = net(image)\n",
    "    \n",
    "    loss1 = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    loss = loss1(torch.squeeze(output_top, dim=0), mask1) + loss1(torch.squeeze(output_bot, dim=0), mask2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    print(f'[Epoch: {epoch + 1},sample: {i + 1:5d}] loss: {running_loss/ (i+1)}')\n",
    "  \n",
    "  \n",
    "#   net.eval()\n",
    "#   loss = 0\n",
    "#   with torch.no_grad():\n",
    "#       for i, (image, mask1, mask2) in enumerate(test_loader):\n",
    "#           output_top, output_bot = net(image)  \n",
    "#           loss1 = nn.BCEWithLogitsLoss()\n",
    "#           loss += loss1(torch.squeeze(output_top, dim=0), mask1) + loss1(torch.squeeze(output_bot, dim=0), mask2)\n",
    "  \n",
    "#   val_loss = loss / len(test_loader)\n",
    "#   print(\"Epoch {}, val_loss=\".format(epoch), val_loss)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "YMCA_WB_TL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
